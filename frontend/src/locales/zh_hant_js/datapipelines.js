export const dataPipelines = {
  "toSel": "請選擇",
  "toInput": "請輸入",
  "noData": "暫無數據",
  "dataProcessing": "數據處理",
  "processingResult": "處理結果",
  "algorithmTemplate": "算法模板",
  "myAlgorithmTemplate": "我的算法模板",
  "dataProcessingDescription": "數據處理可支持用戶使用不同的模型算子，針對大模型所用的數據進行處理，包括數據清洗、自動數據增強及分析等處理方式，用戶可通過數據處理來獲取更高質量的數據",
  "searchProcessing": "搜索處理任務",
  "search": "搜索",
  "taskCategories": "任務分類",
  "allCategories": "全部分類",
  "createTask": "創建任務",
  "taskList": "任務列表",
  "taskName": "任務名稱",

  "createTime": "創建時間",
  "dataAmount": "數據量",
  "finishTime": "完成時間",
  "processedDataAmount": "已處理數據量",
  "processInfo": "處理詳情",
  "processStatus": "運行狀態",
  "processedData": "已處理數據",
  "sessionProcessedResult": "Session處理結果",
  "index": "序號",
  "preSession": "處理前Session",
  "processType": "處理方式",
  "afterSession": "處理後Session",
  "taskLog": "任務日誌",
  "logName": "日誌名稱",
  "downloadLog": "下載日誌",
  "others": "其他",
  "replace": "替換",
  "deduplicate": "去重",
  "remove": "刪除",
  "data_refine": "數據處理",
  "data_generation": "數據生成",
  "data_enhancement": "數據增強",

  "taskType": "任務類型",
  "dataCleaning": "數據清洗",
  "processingStatus": "處理狀態",
  "processingText": "處理字段",
  "inProgress": "處理中",
  "completed": "已完成",
  "dataSource": "數據來源",
  "dataSourceBranch": "數據來源分支",
  "dataFlow": "數據流向",
  "startTime": "開始時間",
  "operations": "操作",
  "delete": "刪除",
  "deleteConfirm": "確認刪除",
  "confirm": "確認",
  "reset": "替換",
  "details": "詳情",
  "algorithmTemplateDescription": "算法模版可支持用戶使用多種不同的模型算子組成工作流，完成數據清洗、自動數據增強及分析等工作。",
  "taskTemplate": "任務模板",
  "templateName": "模板名稱",
  "templateDescription": "模板描述",
  "searchTaskTemplate": "搜索任務模板",
  "create": "創建",
  "edit": "修改",
  "type": "類型",
  "createTemplate": "創建模板",
  "editTemplate": "修改模板",
  "general": "通用",
  "dataCleaningDescription": "通過去重、去敏等多種算子，清洗數據，使數據滿足使用需求",
  "dataAugmentation": "數據增強",
  "dataAugmentationDescription": "基於種子數據自動化生成更多數據，可用於訓練數據生成，支持自定義參數及Prompt",
  "textClassification": "文本分類",
  "textClassificationDescription": "增強文本分類任務的訓練數據，適用於情感分類、標籤分類、商品分類等場景",
  "textExtraction": "文本抽取",
  "textExtractionDescription": "增強文本抽取類任務的訓練數據，適用於特定格式抽取、實體抽取、要素提取等場景",
  "textGeneration": "文本創作",
  "textGenerationDescription": "增強文本創作類任務的訓練數據，適用於新聞寫作、廣告稿生成、寫作內容風格化等場景",
  "apply": "使用",
  "newTask": "新建任務",
  "pushToOriginalDataset": "推送到原數據集",
  "pushToOriginalDatasetDescription": "推送到原數據集後，將以新提交的方式推送到原始數據集repo中",
  "pushToNewDataset": "推送到新數據集",
  "pushToSelectedDatasetDescription": "數據清洗完成後，將推送到所選數據集",
  "targetDataset": "目標數據集名稱",
  "predefinedOperatorSelection": "預置算子選擇",
  "predefinedOperator": "預置算子",
  "peratorTip": "目前支持多種 Mapper、Filter、Deduplicator 類型的預置算子",
  "publishAsNewTemplate": "發布為新模版",
  "executionOrder": "執行順序",
  "enableOrNot": "是否開啟",
  "addOperator": "添加算子",
  "operatorType": "算子類型",
  "operatorName": "算子名稱",
  "textNormalization": "文本標準化",
  "removeSpecialContent": "特殊內容移除",
  "maskSensitiveInformation": "敏感信息打碼",
  "specialCharacterRatioFiltering": "特殊字符佔比過濾",
  "sensitiveWordFiltering": "敏感詞過濾",
  "nGramRepetitionRatioFiltering": "N-Gram重複比率過濾",
  "lengthFiltering": "長度過濾",
  "md5Deduplication": "MD5去重",
  "articleSimilarityDeduplication": "文章相似度去重",
  "toxicityRemoval": "毒性去除",
  "operatorConfiguration": "算子配置",
  "unicodeTextNormalization": "Unicode文本標準化",
  "convertTraditionalChineseToSimplifiedChinese": "繁體轉簡體",
  "removeURLLinks": "去除URL鏈接",
  "removeInvisibleCharacters": "去除不可見字符",
  "removeHtmlTagsAndParseHtmlContent": "去除html格式字符並解析出html文本",
  "maximumRatio": "比例最大值",
  "lengthN": "長度N",
  "minimumLength": "長度最小值",
  "characters": "字符",
  "windowLength": "窗口長度",
  "description": "描述",
  "textNormalizationDesc": "文本Unicode標準化和繁體轉中文",
  "removeSpecialContentDesc": "移除文本中的特殊內容，例如文章中的url、不可見字符、html格式字符等",
  "maskSensitiveInformationDesc": "將敏感信息打碼，例如將郵箱地址字符替換成[EMAIL]，手機電話號碼替換成[TELEPHONE]或[MOBILEPHONE]，身份證號碼替換成[IDNUM]",
  "specialCharacterRatioFilteringDesc": "根據特殊字符佔比過濾文本，保留特殊字符個數佔文本總長度比例不超過設定閾值的樣本，特殊字符包括標點符號，數字，空格符號，emoji表情包等，超過設定比例的數據樣本將被過濾",
  "sensitiveWordFilteringDesc": "過濾掉帶有敏感詞的樣本",
  "nGramRepetitionRatioFilteringDesc": "保留字符級N-Gram重複比率不超過設定閾值的樣本，超過閾值的樣本將被過濾",
  "lengthFilteringDesc": "根據文本長度過濾數據，長度範圍之外的數據將被過濾",
  "md5DeduplicationDesc": "根據文本生成的MD5值對比去重，MD5校驗一致的樣本將被過濾",
  "articleSimilarityDeduplicationDesc": "使用SimHash算法計算文本間的相似度，相似度超過閾值樣本將被過濾",
  "toxicityRemovalDesc": "自動檢測分析並去除數據中敏感、不合規的內容，本算子僅對數據內容進行分析、處理，不保存、保留任何處理前、處理後的數據內容",
  "previewBefore": "效果預覽（清洗前）",
  "previewAfter": "效果預覽（清洗後）",
  "creationCompleted": "創建完成",
  "cancel": "取消",
  "templateNameExists": "模板名稱已存在，請使用其他名稱",
  "Queued": "待處理",
  "Processing": "處理中",
  "Finished": "已完成",
  "Failed": "失敗",
  "Timeout": "超時",
  "sessionDel": "Session已刪除",

  "toolsTit": "工具池",
  "toolsDec": "Dataflow 工具池是一個一站式多模態數據處理系統，可使數據質量更高、更有價值、更適合大模型處理。",
  "toolsSearch": "搜索工具",
  "toolsType": "工具分類",
  "toolsName": "工具名稱",
  "toolsUse": "使用工具",
  "taskType1": "算子",
  "taskType2": "工具",
  "log": "日誌",
  "toolsTab1": "內部工具",
  "toolsTab2": "外部工具",

  "analysis_common_internal": "通用分析工具",
  "dataset_spliter_by_language_preprocess_internal": "數據集按語言分割預處理工具",
  "prepare_dataset_from_repo_preprocess_internal": "從代碼倉庫準備數據集預處理工具",
  "raw_alpaca_cot_merge_add_meta_preprocess_internal": "原始Alpaca-Cot數據合併與元數據添加預處理工具",
  "raw_arxiv_to_jsonl_preprocess_internal": "原始arXiv數據轉換為JSONL預處理工具",
  "raw_stackexchange_to_jsonl_preprocess_internal": "原始Stack Exchange數據轉換為JSONL預處理工具",
  "reformat_csv_nan_value_preprocess_internal": "CSV文件NaN值重格式化預處理工具",
  "reformat_jsonl_nan_value_preprocess_internal": "JSONL文件NaN值重格式化預處理工具",
  "serialize_meta_preprocess_internal": "元數據序列化預處理工具",
  "count_token_postprocess_internal": "令牌計數後處理工具",
  "data_mixture_postprocess_internal": "數據混合後處理工具",
  "deserialize_meta_postprocess_internal": "元數據反序列化後處理工具",
  "quality_classifier_common_internal": "質量分類器通用",
  "opencsg_data_extraction_preprocess_internal": "開放計算系統數據提取預處理",
  "opencsg_scrape_url_data_preprocess_internal": "開放計算系統抓取 URL 數據預處理",

  "analysis_common_internal_dec": "此分析器類用於分析特定數據集。它會為配置文件中的所有過濾操作計算統計數據，對這些統計數據應用多種分析（如整體分析、逐列分析等），並生成分析結果（統計表、分佈圖等），幫助用戶更好地理解輸入數據集。",
  "dataset_spliter_by_language_preprocess_internal_dec": "從源目錄加載數據集，然後使用名為 LanguageIDScoreFilter 的操作過濾器進行語言識別，最後按語言分割數據集並保存。",
  "prepare_dataset_from_repo_preprocess_internal_dec": "從代碼倉庫中準備數據集，格式包括：倉庫名稱、倉庫中的文件路徑、文件內容。",
  "raw_alpaca_cot_merge_add_meta_preprocess_internal_dec": "將從Hugging Face下載的原始Alpaca-Cot數據轉換為JSONL文件，合併指令/輸入/輸出文本，並添加元數據信息。",
  "raw_arxiv_to_jsonl_preprocess_internal_dec": "將原始arXiv數據（gzipped tar文件）轉換為JSONL格式。",
  "raw_stackexchange_to_jsonl_preprocess_internal_dec": "將從Archive（參考：https://archive.org/download/stackexchange）下載的原始Stack Exchange數據轉換為多個JSONL文件。",
  "reformat_csv_nan_value_preprocess_internal_dec": "使用Hugging Face加載可能包含NaN值的CSV或TSV文件，並可通過設置額外參數（如設置 	keep_default_na 為False）進行處理。",
  "reformat_jsonl_nan_value_preprocess_internal_dec": "重格式化可能包含NaN值的JSONL文件。遍歷JSONL文件，找到第一個不包含NaN的對象作為參考特徵類型，並將其設置為加載所有JSONL文件時的基準。",
  "serialize_meta_preprocess_internal_dec": "序列化JSONL文件中除用戶指定字段以外的所有字段，確保即使JSONL文件中每行文本格式不一致，數據集仍可正常加載。",
  "count_token_postprocess_internal_dec": "統計給定數據集和分詞器的令牌數量。目前僅支持JSONL格式。",
  "data_mixture_postprocess_internal_dec": "將多個數據集混合成一個數據集。隨機選擇每個數據集的樣本並混合這些樣本，然後導出為新的混合數據集。支持的格式包括：[“jsonl”, “json”, “parquet”]。",
  "deserialize_meta_postprocess_internal_dec": "對JSONL文件中的指定字段進行反序列化處理。",
  "quality_classifier_common_internal_dec": "本質量分類器類用於預測數據集中文檔的評分。它將計算所有行的分數，並為每一行提供兩列：分數（score）和是否保留（should_keep），以幫助用戶決定應該刪除哪一行。默認情況下，如果分數高於 0.9，則將該行標記為 should_keep=1。",
 "opencsg_data_extraction_preprocess_internal_dec": "一個高質量的工具，用於將 PDF 轉換為 Markdown 和 JSON",
  "opencsg_scrape_url_data_preprocess_internal_dec": "基於大型語言模型的網站和本地文檔（XML、HTML、JSON 等）的數據抓取工具",
}