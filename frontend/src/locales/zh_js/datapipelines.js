export const dataPipelines = {
  "toSel": "请选择",
  "toInput": "请输入",
  "noData": "暂无数据",
  "dataProcessing": "数据处理",
  "processingResult": "处理结果",
  "algorithmTemplate": "算法模板",
  "myAlgorithmTemplate": "我的算法模板",
  "dataProcessingDescription": "数据处理可支持用户使用不同的模型算子，针对大模型所用的数据进行处理，包括数据清洗、自动数据增强及分析等处理方式，用户可通过数据处理来获取更高质量的数据",
  "searchProcessing": "搜索处理任务",
  "search": "搜索",
  "taskCategories": "任务分类",
  "allCategories": "全部分类",
  "createTask": "创建任务",
  "taskList": "任务列表",
  "taskName": "任务名称",

  "createTime": "创建时间",
  "dataAmount": "数据量",
  "finishTime": "完成时间",
  "processedDataAmount": "已处理数据量",
  "processInfo": "处理详情",
  "processStatus": "运行状态",
  "processedData": "已处理数据",
  "sessionProcessedResult": "Session处理结果",
  "index": "序号",
  "preSession": "处理前Session",
  "processType": "处理方式",
  "afterSession": "处理后Session",
  "taskLog": "任务日志",
  "logName": "日志名称",
  "downloadLog": "下载日志",
  "others": "其他",
  "replace": "替换",
  "deduplicate": "去重",
  "remove": "删除",
  "data_refine": "数据处理",
  "data_generation": "数据生成",
  "data_enhancement": "数据增强",

  "taskType": "任务类型",
  "dataCleaning": "数据清洗",
  "processingStatus": "处理状态",
  "processingText": "处理字段",
  "inProgress": "处理中",
  "completed": "已完成",
  "dataSource": "数据来源",
  "dataSourceBranch": "数据来源分支",
  "dataFlow": "数据流向",
  "startTime": "开始时间",
  "operations": "操作",
  "delete": "删除",
  "deleteConfirm": "确认删除",
  "confirm": "确认",
  "reset": "替换",
  "details": "详情",
  "algorithmTemplateDescription": "算法模版可支持用户使用多种不同的模型算子组成工作流，完成数据清洗、自动数据增强及分析等工作。",
  "taskTemplate": "任务模板",
  "templateName": "模板名称",
  "templateDescription": "模板描述",
  "searchTaskTemplate": "搜索任务模板",
  "create": "创建",
  "edit": "修改",
  "type": "类型",
  "createTemplate": "创建模板",
  "editTemplate": "修改模板",
  "general": "通用",
  "dataCleaningDescription": "通过去重、去敏等多种算子，清洗数据，使数据满足使用需求",
  "dataAugmentation": "数据增强",
  "dataAugmentationDescription": "基于种子数据自动化生成更多数据，可用于训练数据生成，支持自定义参数及Prompt",
  "textClassification": "文本分类",
  "textClassificationDescription": "增强文本分类任务的训练数据，适用于情感分类、标签分类、商品分类等场景",
  "textExtraction": "文本抽取",
  "textExtractionDescription": "增强文本抽取类任务的训练数据，适用于特定格式抽取、实体抽取、要素提取等场景",
  "textGeneration": "文本创作",
  "textGenerationDescription": "增强文本创作类任务的训练数据，适用于新闻写作、广告稿生成、写作内容风格化等场景",
  "apply": "使用",
  "newTask": "新建任务",
  "pushToOriginalDataset": "推送到原数据集",
  "pushToOriginalDatasetDescription": "推送到原数据集后，将以新提交的方式推送到原始数据集repo中",
  "pushToNewDataset": "推送到新数据集",
  "pushToSelectedDatasetDescription": "数据清洗完成后，将推送到所选数据集",
  "targetDataset": "目标数据集名称",
  "predefinedOperatorSelection": "预置算子选择",
  "predefinedOperator": "预置算子",
  "peratorTip": "目前支持多种 Mapper、Filter、Deduplicator 类型的预置算子",
  "publishAsNewTemplate": "发布为新模版",
  "executionOrder": "执行顺序",
  "enableOrNot": "是否开启",
  "addOperator": "添加算子",
  "operatorType": "算子类型",
  "operatorName": "算子名称",
  "textNormalization": "文本标准化",
  "removeSpecialContent": "特殊内容移除",
  "maskSensitiveInformation": "敏感信息打码",
  "specialCharacterRatioFiltering": "特殊字符占比过滤",
  "sensitiveWordFiltering": "敏感词过滤",
  "nGramRepetitionRatioFiltering": "N-Gram重复比率过滤",
  "lengthFiltering": "长度过滤",
  "md5Deduplication": "MD5去重",
  "articleSimilarityDeduplication": "文章相似度去重",
  "toxicityRemoval": "毒性去除",
  "operatorConfiguration": "算子配置",
  "unicodeTextNormalization": "Unicode文本标准化",
  "convertTraditionalChineseToSimplifiedChinese": "繁体转简体",
  "removeURLLinks": "去除URL链接",
  "removeInvisibleCharacters": "去除不可见字符",
  "removeHtmlTagsAndParseHtmlContent": "去除html格式字符并解析出html文本",
  "maximumRatio": "比例最大值",
  "lengthN": "长度N",
  "minimumLength": "长度最小值",
  "characters": "字符",
  "windowLength": "窗口长度",
  "description": "描述",
  "textNormalizationDesc": "文本Unicode标准化和繁体转中文",
  "removeSpecialContentDesc": "移除文本中的特殊内容，例如文章中的url、不可见字符、html格式字符等",
  "maskSensitiveInformationDesc": "将敏感信息打码，例如将邮箱地址字符替换成[EMAIL]，手机电话号码替换成[TELEPHONE]或[MOBILEPHONE]，身份证号码替换成[IDNUM]",
  "specialCharacterRatioFilteringDesc": "根据特殊字符占比过滤文本，保留特殊字符个数占文本总长度比例不超过设定阈值的样本，特殊字符包括标点符号，数字，空格符号，emoji表情包等，超过设定比例的数据样本将被过滤",
  "sensitiveWordFilteringDesc": "过滤掉带有敏感词的样本",
  "nGramRepetitionRatioFilteringDesc": "保留字符级N-Gram重复比率不超过设定阈值的样本，超过阈值的样本将被过滤",
  "lengthFilteringDesc": "根据文本长度过滤数据，长度范围之外的数据将被过滤",
  "md5DeduplicationDesc": "根据文本生成的MD5值对比去重，MD5校验一致的样本将被过滤",
  "articleSimilarityDeduplicationDesc": "使用SimHash算法计算文本间的相似度，相似度超过阈值样本将被过滤",
  "toxicityRemovalDesc": "自动检测分析并去除数据中敏感、不合规的内容，本算子仅对数据内容进行分析、处理，不保存、保留任何处理前、处理后的数据内容",
  "previewBefore": "效果预览（清洗前）",
  "previewAfter": "效果预览（清洗后）",
  "creationCompleted": "创建完成",
  "cancel": "取消",
  "templateNameExists": "模板名称已存在，请使用其他名称",
  "Queued": "待处理",
  "Processing": "处理中",
  "Finished": "已完成",
  "Failed": "失败",
  "Timeout": "超时",
  "sessionDel": "Session已删除",

  "toolsTit": "工具池",
  "toolsDec": "Dataflow 工具池是一个一站式多模态数据处理系统，可使数据质量更高、更有价值、更适合大模型处理。",
  "toolsSearch": "搜索工具",
  "toolsType": "工具分类",
  "toolsName": "工具名称",
  "toolsUse": "使用工具",
  "taskType1": "算子",
  "taskType2": "工具",
  "log": "日志",
  "toolsTab1": "内部工具",
  "toolsTab2": "外部工具",

  "analysis_common_internal": "通用分析工具",
  "dataset_spliter_by_language_preprocess_internal": "数据集按语言分割预处理工具",
  "prepare_dataset_from_repo_preprocess_internal": "从代码仓库准备数据集预处理工具",
  "raw_alpaca_cot_merge_add_meta_preprocess_internal": "原始Alpaca-Cot数据合并与元数据添加预处理工具",
  "raw_arxiv_to_jsonl_preprocess_internal": "原始arXiv数据转换为JSONL预处理工具",
  "raw_stackexchange_to_jsonl_preprocess_internal": "原始Stack Exchange数据转换为JSONL预处理工具",
  "reformat_csv_nan_value_preprocess_internal": "CSV文件NaN值重格式化预处理工具",
  "reformat_jsonl_nan_value_preprocess_internal": "JSONL文件NaN值重格式化预处理工具",
  "serialize_meta_preprocess_internal": "元数据序列化预处理工具",
  "count_token_postprocess_internal": "令牌计数后处理工具",
  "data_mixture_postprocess_internal": "数据混合后处理工具",
  "deserialize_meta_postprocess_internal": "元数据反序列化后处理工具",
  "quality_classifier_common_internal": "质量分类器通用",
  "opencsg_data_extraction_preprocess_internal": "开放计算系统数据提取预处理",
  "opencsg_scrape_url_data_preprocess_internal": "开放计算系统抓取 URL 数据预处理",

  "analysis_common_internal_dec": "此分析器类用于分析特定数据集。它会为配置文件中的所有过滤操作计算统计数据，对这些统计数据应用多种分析（如整体分析、逐列分析等），并生成分析结果（统计表、分布图等），帮助用户更好地理解输入数据集。",
  "dataset_spliter_by_language_preprocess_internal_dec": "从源目录加载数据集，然后使用名为 LanguageIDScoreFilter 的操作过滤器进行语言识别，最后按语言分割数据集并保存。",
  "prepare_dataset_from_repo_preprocess_internal_dec": "从代码仓库中准备数据集，格式包括：仓库名称、仓库中的文件路径、文件内容。",
  "raw_alpaca_cot_merge_add_meta_preprocess_internal_dec": "将从Hugging Face下载的原始Alpaca-Cot数据转换为JSONL文件，合并指令/输入/输出文本，并添加元数据信息。",
  "raw_arxiv_to_jsonl_preprocess_internal_dec": "将原始arXiv数据（gzipped tar文件）转换为JSONL格式。",
  "raw_stackexchange_to_jsonl_preprocess_internal_dec": "将从Archive（参考：https://archive.org/download/stackexchange）下载的原始Stack Exchange数据转换为多个JSONL文件。",
  "reformat_csv_nan_value_preprocess_internal_dec": "使用Hugging Face加载可能包含NaN值的CSV或TSV文件，并可通过设置额外参数（如设置 	keep_default_na 为False）进行处理。",
  "reformat_jsonl_nan_value_preprocess_internal_dec": "重格式化可能包含NaN值的JSONL文件。遍历JSONL文件，找到第一个不包含NaN的对象作为参考特征类型，并将其设置为加载所有JSONL文件时的基准。",
  "serialize_meta_preprocess_internal_dec": "序列化JSONL文件中除用户指定字段以外的所有字段，确保即使JSONL文件中每行文本格式不一致，数据集仍可正常加载。",
  "count_token_postprocess_internal_dec": "统计给定数据集和分词器的令牌数量。目前仅支持JSONL格式。",
  "data_mixture_postprocess_internal_dec": "将多个数据集混合成一个数据集。随机选择每个数据集的样本并混合这些样本，然后导出为新的混合数据集。支持的格式包括：[“jsonl”, “json”, “parquet”]。",
  "deserialize_meta_postprocess_internal_dec": "对JSONL文件中的指定字段进行反序列化处理。",
  "quality_classifier_common_internal_dec": "本质量分类器类用于预测数据集中文档的评分。它将计算所有行的分数，并为每一行提供两列：分数（score）和是否保留（should_keep），以帮助用户决定应该删除哪一行。默认情况下，如果分数高于 0.9，则将该行标记为 should_keep=1。",
 "opencsg_data_extraction_preprocess_internal_dec": "一个高质量的工具，用于将 PDF 转换为 Markdown 和 JSON",
  "opencsg_scrape_url_data_preprocess_internal_dec": "基于大型语言模型的网站和本地文档（XML、HTML、JSON 等）的数据抓取工具",
}
