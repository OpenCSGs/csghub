{
    "chinese_convert_mapper": {
        "name": "Chinese Converter",
        "description": "Mapper to convert Chinese between Traditional Chinese, Simplified Chinese and Japanese Kanji.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "è¿™æ˜¯å‡ ä¸ªç®€ä½“å­—ï¼Œä¼šè¢«è½¬æ¢ä¸ºç¹ä½“å­—",
            "after": "é€™æ˜¯å¹¾å€‹ç°¡é«”å­—ï¼Œæœƒè¢«è½‰æ›çˆ²ç¹é«”å­—"
        },
        "params": [
            {
                "name": "mode",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "s2t",
                        "label": "s2t"
                    },
                    {
                        "key": "t2s",
                        "label": "t2s"
                    },
                    {
                        "key": "s2tw",
                        "label": "s2tw"
                    },
                    {
                        "key": "tw2s",
                        "label": "tw2s"
                    },
                    {
                        "key": "s2hk",
                        "label": "s2hk"
                    },
                    {
                        "key": "hk2s",
                        "label": "hk2s"
                    },
                    {
                        "key": "s2twp",
                        "label": "s2twp"
                    },
                    {
                        "key": "tw2sp",
                        "label": "tw2sp"
                    },
                    {
                        "key": "t2tw",
                        "label": "t2tw"
                    },
                    {
                        "key": "tw2t",
                        "label": "tw2t"
                    },
                    {
                        "key": "hk2t",
                        "label": "hk2t"
                    },
                    {
                        "key": "t2hk",
                        "label": "t2hk"
                    },
                    {
                        "key": "t2jp",
                        "label": "t2jp"
                    },
                    {
                        "key": "jp2t",
                        "label": "jp2t"
                    }
                ],
                "value": "t2s"
            }
        ]
    },
    "clean_copyright_mapper": {
        "name": "Copyright Cleaner",
        "description": "Mapper to clean copyright comments at the beginning of the text\n    samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "è¿™æ˜¯ä¸€æ®µ /* å¤šè¡Œæ³¨é‡Š\næ³¨é‡Šå†…å®¹copyright\n*/ çš„æ–‡æœ¬ã€‚å¦å¤–è¿˜æœ‰ä¸€äº› // å•è¡Œæ³¨é‡Šã€‚",
            "after": "è¿™æ˜¯ä¸€æ®µ  çš„æ–‡æœ¬ã€‚å¦å¤–è¿˜æœ‰ä¸€äº› // å•è¡Œæ³¨é‡Šã€‚"
        },
        "params": []
    },
    "clean_email_mapper": {
        "name": "Email Cleaner",
        "description": "Mapper to clean email in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "happy day euqdh@cjqi.com",
            "after": "happy day "
        },
        "params": []
    },
    "clean_html_mapper": {
        "name": "HTML Code Cleaner",
        "description": "Mapper to clean html code in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "<a href='https://www.example.com/file.html?;name=Test' rel='noopener noreferrer' target='_blank'>Test</a>",
            "after": "Test"
        },
        "params": []
    },
    "clean_ip_mapper": {
        "name": "IP Cleaner",
        "description": "Mapper to clean ipv4 and ipv6 address in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "ftp://example.com/188.46.244.216my-page.html",
            "after": "ftp://example.com/my-page.html"
        },
        "params": []
    },
    "clean_links_mapper": {
        "name": "Link Cleaner",
        "description": "Mapper to clean links like http/https/ftp in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "è¿™æ˜¯ä¸ªæµ‹è¯•,https://example.com/my-page.html?param1=value1&param2=value2",
            "after": "è¿™æ˜¯ä¸ªæµ‹è¯•,"
        },
        "params": []
    },
    "expand_macro_mapper": {
        "name": "Expand Macro Definitions",
        "description": "Mapper to expand macro definitions in the document body of Latex\n    samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "\\documentclass{article}\n% Recommended, but optional, packages for figures and better typesetting:\n\\usepackage{microtype}\n\\usepackage{graphicx}\n\n% Attempt to make hyperref and algorithmic work together better:\n\\newcommand{\\theHalgorithm}{\\arabic{algorithm}}\n% For theorems and such\n\\usepackage{amsmath}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% THEOREMS\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\theoremstyle{plain}\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\theoremstyle{definition}\n\n\\usepackage[textsize=small]{todonotes}\n\\setuptodonotes{inline}\n\n\\usepackage{makecell}\n\\newcommand{\\cmark}{\\ding{51}\\xspace}%\n\\newcommand{\\xmark}{\\ding{55}\\xspace}%\n\n\\def \\alambic {\\includegraphics[height=1.52ex]{img/alembic-crop.pdf}\\xspace}\n\n\\newcommand\\binke[1]{{\\color{blue} \\footnote{\\color{blue}binke: #1}} }\n\\newcommand\\Zerocost{Zero-cost}\n\\newcommand\\imagenet{ImageNet}\n\n\\begin{document}\n\n\\begin{abstract}\nThe wide\n\\end{abstract}\n\\section{Introduction}\n\\label{introduction}\nThe main contributions are summarized as follows:\n\\section{Background and Related Work}\\label{background}\n\\subsection{One-Shot NAS} In one-shot NAS\n\\section{PreNAS}\\label{method}In this\n\\subsection{One-Shot NAS with Preferred Learning}\nIn the specialization stage, the optimal architectures under given  resource constraints can be directly obtained:\n\\begin{equation}\n\\widetilde{\\mathcal{A}}^* = \\widetilde{\\mathcal{A}} .\n\\end{equation}\n\\subsection{Zero-Cost Transformer Selector}\\label{sub:layerNorm}\n\\subsection{Performance Balancing} We discuss\n\\section{Experiments}\\label{experiments}\n\\subsection{Setup}\n\\subsection{Main Results}\\label{sec:sota}\n\\subsection{Analysis and Ablation study}\\label{ablation}\n\\begin{figure}[t]\n\\vskip 0.1in\n    \\centering\n    \\subfigure[Search spaces]{\\includegraphics[width=0.36\\linewidth]{img/search_space.pdf}\\label{fg:search_space:a}}%\n    \\hfil%\n    \\subfigure[Error distributions]{\\includegraphics[width=0.58\\linewidth]{img/cumulation.pdf}\\label{fg:search_space:b}}\n    \\caption{Model quality}\n\\vskip -0.1in\n\\end{figure}\n\\paragraph{Effect of Performance Balancing} During\n\\subsection{Transfer Learning Results}\n\\subsection{CNN Results} in terms of similar FLOPs.\n\\FloatBarrier\n\\section{Conclusion}\\label{conclusion} In this\n% Acknowledgements should only appear in the accepted version.\n\\bibliography{ref}\n\\bibliographystyle{icml2023}\n\\clearpage\n\\appendix\n\\onecolumn\n\\section{Statistical}\n\\label{appendix:snipAnalysis} We analyze\n\\section{The Greedy Algorithm}\n\\label{appendix:greedy}\n\\section{Regularization \\& Data Augmentation}\\label{appendix:aug}\n\\renewcommand{\\arraystretch}{1.2}\n\\end{document}\n",
            "after": "\\documentclass{article}\n% Recommended, but optional, packages for figures and better typesetting:\n\\usepackage{microtype}\n\\usepackage{graphicx}\n\n% Attempt to make hyperref and algorithmic work together better:\n\\newcommand{\\arabic{algorithm}}{\\arabic{algorithm}}\n% For theorems and such\n\\usepackage{amsmath}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% THEOREMS\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\theoremstyle{plain}\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\theoremstyle{definition}\n\n\\usepackage[textsize=small]{todonotes}\n\\setuptodonotes{inline}\n\n\\usepackage{makecell}\n\\newcommand{\\cmark}{\\ding{51}\\xspace}%\n\\newcommand{\\xmark}{\\ding{55}\\xspace}%\n\n\\def \\includegraphics[height=1.52ex]{img/alembic-crop.pdf}\\xspace {\\includegraphics[height=1.52ex]{img/alembic-crop.pdf}\\xspace}\n\n\\newcommand\\binke[1]{{\\color{blue} \\footnote{\\color{blue}binke: #1}} }\n\\newcommand\\Zerocost{Zero-cost}\n\\newcommand\\imagenet{ImageNet}\n\n\\begin{document}\n\n\\begin{abstract}\nThe wide\n\\end{abstract}\n\\section{Introduction}\n\\label{introduction}\nThe main contributions are summarized as follows:\n\\section{Background and Related Work}\\label{background}\n\\subsection{One-Shot NAS} In one-shot NAS\n\\section{PreNAS}\\label{method}In this\n\\subsection{One-Shot NAS with Preferred Learning}\nIn the specialization stage, the optimal architectures under given  resource constraints can be directly obtained:\n\\begin{equation}\n\\widetilde{\\mathcal{A}}^* = \\widetilde{\\mathcal{A}} .\n\\end{equation}\n\\subsection{Zero-Cost Transformer Selector}\\label{sub:layerNorm}\n\\subsection{Performance Balancing} We discuss\n\\section{Experiments}\\label{experiments}\n\\subsection{Setup}\n\\subsection{Main Results}\\label{sec:sota}\n\\subsection{Analysis and Ablation study}\\label{ablation}\n\\begin{figure}[t]\n\\vskip 0.1in\n    \\centering\n    \\subfigure[Search spaces]{\\includegraphics[width=0.36\\linewidth]{img/search_space.pdf}\\label{fg:search_space:a}}%\n    \\hfil%\n    \\subfigure[Error distributions]{\\includegraphics[width=0.58\\linewidth]{img/cumulation.pdf}\\label{fg:search_space:b}}\n    \\caption{Model quality}\n\\vskip -0.1in\n\\end{figure}\n\\paragraph{Effect of Performance Balancing} During\n\\subsection{Transfer Learning Results}\n\\subsection{CNN Results} in terms of similar FLOPs.\n\\FloatBarrier\n\\section{Conclusion}\\label{conclusion} In this\n% Acknowledgements should only appear in the accepted version.\n\\bibliography{ref}\n\\bibliographystyle{icml2023}\n\\clearpage\n\\appendix\n\\onecolumn\n\\section{Statistical}\n\\label{appendix:snipAnalysis} We analyze\n\\section{The Greedy Algorithm}\n\\label{appendix:greedy}\n\\section{Regularization \\& Data Augmentation}\\label{appendix:aug}\n\\renewcommand{\\arraystretch}{1.2}\n\\end{document}\n"
        },
        "params": []
    },
    "generate_code_qa_pair_mapper": {
        "name": "Convert code to QA pair",
        "description": "Mapper to generate new instruction data based on code.\n    ",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "def hello_world():\n    print(\"Hello, World!\")\nhello_world()",
            "after": "message:[{\"input\": \"create hello word function by python\", \"response\": \"def hello_world():\n    print(\"Hello, World!\")\nhello_world()\" }]"
        },
        "status": "Queued",
        "data_lines": 0,
        "data": {},
        "params": [
            {
                "name": "hf_model",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "AIWizards/Llama2-Chinese-7b-Chat",
                        "label": "AIWizards/Llama2-Chinese-7b-Chat"
                    }
                ],
                "value": "AIWizards/Llama2-Chinese-7b-Chat"
            },
            {
                "name": "prompt_template",
                "type": "STRING",
                "option_values": null,
                "value": null
            }
        ]
    },
    "extract_qa_mapper": {
        "name": "QA pair extractor",
        "description": "\n    Mapper to extract question and answer pair from text samples.\n    Recommended model list: [\n        'alibaba-pai/pai-llama3-8b-doc2qa',\n        'alibaba-pai/pai-baichuan2-7b-doc2qa',\n        'alibaba-pai/pai-qwen1_5-4b-doc2qa',\n        'alibaba-pai/pai-qwen1_5-7b-doc2qa',\n        'alibaba-pai/pai-qwen1_5-1b8-doc2qa',\n        'alibaba-pai/pai-qwen1_5-0b5-doc2qa'\n    ]\n    These recommended models are all trained with Chinese data\n    and are suitable for Chinese.\n    ",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "è’™å¤å›½çš„é¦–éƒ½æ˜¯ä¹Œå…°å·´æ‰˜ï¼ˆUlaanbaatarï¼‰",
            "after": "Human: è¯·é—®è’™å¤å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼ŸAssistant: ä½ å¥½ï¼Œæ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œè’™å¤å›½çš„é¦–éƒ½æ˜¯ä¹Œå…°å·´æ‰˜ï¼ˆUlaanbaatarï¼‰"
        },
        "params": [
            {
                "name": "hf_model",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "alibaba-pai/pai-qwen1_5-7b-doc2qa",
                        "label": "alibaba-pai/pai-qwen1_5-7b-doc2qa"
                    }
                ],
                "value": "alibaba-pai/pai-qwen1_5-7b-doc2qa"
            }
        ]
    },
    "fix_unicode_mapper": {
        "name": "Unicode Corrector",
        "description": "Mapper to fix unicode errors in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "The Mona Lisa doesnÃƒÆ’Ã‚Â¢ÃƒÂ¢Ã¢â‚¬Å¡Ã‚Â¬ÃƒÂ¢Ã¢â‚¬Å¾Ã‚Â¢t have eyebrows.",
            "after": "The Mona Lisa doesn't have eyebrows."
        },
        "params": [
            {
                "name": "normalization",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "NFC",
                        "label": "NFC"
                    },
                    {
                        "key": "NFKC",
                        "label": "NFKC"
                    },
                    {
                        "key": "NFD",
                        "label": "NFD"
                    },
                    {
                        "key": "NFKD",
                        "label": "NFKD"
                    }
                ],
                "value": "NFC"
            }
        ]
    },
    "nlpaug_en_mapper": {
        "name": "English Augment",
        "description": "Mapper to simply augment samples in English based on nlpaug library.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "I am going to the park.",
            "after": "I am proceeding to the park."
        },
        "params": [
            {
                "name": "delete_random_word",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "swap_random_word",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "spelling_error_word",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "split_random_word",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "keyboard_error_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "ocr_error_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "delete_random_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "swap_random_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "insert_random_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            }
        ]
    },
    "nlpcda_zh_mapper": {
        "name": "Chinese Augment",
        "description": "Mapper to simply augment samples in Chinese based on nlpcda library.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "è¿™é‡Œä¸€å…±æœ‰5ç§ä¸åŒçš„æ•°æ®å¢å¼ºæ–¹æ³•",
            "after": "è¿™é‡Œä¸€å…±æœ‰ä¼ç§ä¸åŒçš„æ•°æ®å¢å¼ºæ–¹æ³•"
        },
        "params": [
            {
                "name": "replace_similar_word",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "swap_random_word",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "delete_random_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "swap_random_char",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "replace_equivalent_num",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            }
        ]
    },
    "optimize_instruction_mapper": {
        "name": "Instruction Optimizer",
        "description": "Mapper to optimize instruction.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "é±¼é¦™è‚‰ä¸æ€ä¹ˆåšï¼Ÿ",
            "after": "è¯·æä¾›ä¸€ä»½å®Œæ•´çš„â€œé±¼é¦™è‚‰ä¸â€é£Ÿè°±ï¼ŒåŒ…æ‹¬ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯ï¼šæ‰€éœ€ææ–™æ¸…å•ï¼šè¯·åˆ—å‡ºæ‰€æœ‰å¿…è¦çš„ä¸»æ–™å’Œè¾…æ–™ï¼ŒåŒ…æ‹¬è‚‰çš„ç§ç±»å’Œå¤„ç†æ–¹å¼ï¼Œä»¥åŠæ‰€æœ‰è”¬èœå’Œè°ƒå‘³æ–™çš„å…·ä½“é‡ã€‚å‡†å¤‡å·¥ä½œæŒ‡å—ï¼šæè¿°å‡†å¤‡å·¥ä½œçš„å…·ä½“æ­¥éª¤ï¼Œå¦‚è‚‰ä¸çš„è…Œåˆ¶è¿‡ç¨‹ã€è”¬èœçš„åˆ‡å‰²æŠ€å·§ç­‰ã€‚è¯¦ç»†çƒ¹é¥ªæ­¥éª¤ï¼šè¯·æŒ‰ç…§çƒ¹é¥ªçš„é€»è¾‘é¡ºåºï¼Œé€æ­¥è§£é‡Šå¦‚ä½•å°†ææ–™ç‚’åˆ¶æˆé±¼é¦™è‚‰ä¸ï¼ŒåŒ…æ‹¬ç«å€™æ§åˆ¶ã€è°ƒå‘³æ–™æ·»åŠ çš„æ—¶æœºç­‰è¯¦ç»†æ“ä½œã€‚ç››ç›˜å’Œé™ˆè®¾å»ºè®®ï¼šç»™å‡ºå¦‚ä½•å°†å®Œæˆçš„é±¼é¦™è‚‰ä¸è£…ç›˜æ‘†æ”¾ï¼Œä»¥åŠå¯ä»¥æ­é…çš„å…¶ä»–èœå“æˆ–é¥­ç±»æ¨èï¼Œä»¥ä¾¿æå‡æ•´ä½“ç”¨é¤ä½“éªŒã€‚é™„åŠ å°è´´å£«ï¼šå¦‚æœ‰ä»»ä½•ä¸“ä¸šå°çªé—¨æˆ–æ³¨æ„äº‹é¡¹ï¼Œä¾‹å¦‚å¦‚ä½•åˆ‡è‚‰æ›´æ˜“å…¥å‘³ï¼Œæˆ–ç‰¹å®šè°ƒå‘³æ–™çš„é€‰æ‹©å»ºè®®ç­‰ï¼Œä¹Ÿè¯·ä¸€å¹¶æä¾›ã€‚"
        },
        "params": [
            {
                "name": "hf_model",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "alibaba-pai/Qwen2-7B-Instruct-Refine",
                        "label": "alibaba-pai/Qwen2-7B-Instruct-Refine"
                    }
                ],
                "value": "alibaba-pai/Qwen2-7B-Instruct-Refine"
            }
        ]
    },
    "punctuation_normalization_mapper": {
        "name": "Unicode Punctuations Normalizor",
        "description": "Mapper to normalize unicode punctuations to English punctuations in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "ï¼Œã€‚ã€â€â€â€œÂ«Â»ï¼‘ã€ã€Œã€Šã€‹Â´âˆ¶ï¼šï¼Ÿï¼ï¼ˆï¼‰ï¼›â€“â€”ï¼ï½â€™â€¦â”ã€ˆã€‰ã€ã€‘ï¼…â–º",
            "after": ",.,\"\"\"\"\"\"\"\"\"\"'::?!();- - . ~'...-<>[]%-"
        },
        "params": []
    },
    "remove_bibliography_mapper": {
        "name": "Bibliography Cleaner",
        "description": "Mapper to remove bibliography at the end of documents in Latex\n    samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "%%\n%% This is file `sample-sigconf.tex\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{sample-base}\n\\end{document}\n\\endinput\n%%\n%% End of file `sample-sigconf.tex'.\n",
            "after": "%%\n%% This is file `sample-sigconf.tex\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n"
        },
        "params": []
    },
    "remove_comments_mapper": {
        "name": "Comments Cleaner",
        "description": "\n    Mapper to remove comments in different kinds of documents.\n\n    Only support 'tex' for now.\n    ",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "%%\n%% This is file `sample-sigconf.tex',\n%% The first command in your LaTeX source must be the \\documentclass command.\n\\documentclass[sigconf,review,anonymous]{acmart}\n%% NOTE that a single column version is required for \n%% submission and peer review. This can be done by changing\n\\input{math_commands.tex}\n%% end of the preamble, start of the body of the document source.\n\\begin{document}\n%% The \"title\" command has an optional parameter,\n\\title{Hierarchical Cross Contrastive Learning of Visual Representations}\n%%\n%% The \"author\" command and its associated commands are used to define\n%% the authors and their affiliations.\n\\author{Hesen Chen}\n\\affiliation{%\n  \\institution{Alibaba Group}\n  \\city{Beijing}\n  \\country{China}}\n\\email{hesen.chs@alibaba-inc.com}\n%% By default, the full list of authors will be used in the page\n\\begin{abstract}The rapid\n\\end{abstract}\n\\begin{CCSXML}\n\\ccsdesc[500]{Computing methodologies~Image representations}\n%% Keywords. The author(s) should pick words that accurately describe\n\\keywords{self-supervised,  ontrastive Learning, hierarchical projection, cross-level}\n%% page.\n\\begin{teaserfigure}\n\\end{teaserfigure}\n%% This command processes the author and affiliation and title\n\\maketitle\n\\section{Introduction}\n\\begin{itemize}\n\\end{itemize}\n\\section{Related Work}\n\\label{gen_inst} Self-supervised\n\\section{Method}\n\\label{method}In this section,\n\\subsection{Framework} kkk\n\\subsection{Cross Contrastive Loss}\nSince $\\sZ^n$ are extracted\n\\subsection{Implementation details}\n\\textbf{Image augmentations} We use\n\\textbf{Architecture} We use\n\\textbf{Optimization} We adapt \n\\section{Experiments}\n\\label{experiments}In this section\n\\subsection{Linear and Semi-Supervised Evaluations on ImageNet}\n\\textbf{Linear evaluation on ImageNet} We firs\n\\textbf{Semi-supervised learning on ImageNet} We simply\n\\subsection{Transfer to other datasets and tasks}\n\\textbf{Image classification with fixed features} We follow\n\\section{Ablations} We present\n\\subsection{Influence of hierarchical projection head and cross contrastive loss} get out\n\\subsection{Levels and depth of projector network}\n\\end{center}\n\\caption{\\label{figure3} \\textbf{Different way of cross-correlation on 3 level hierarchical projection head.} '=' denotes stop gradient.}\n\\end{figure}\n\\subsection{Analyze of} In this\n\\textbf{Similarity between} Using SimSiam\n\\textbf{Feature similarity} We extracted\n\\section{Conclusion}\nWe propose HCCL\n\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{sample-base}\n\\end{document}\n\\endinput\n%%\n%% End of file `sample-sigconf.tex'.\n",
            "after": "\\documentclass[sigconf,review,anonymous]{acmart}\n\\input{math_commands.tex}\n\\begin{document}\n\\title{Hierarchical Cross Contrastive Learning of Visual Representations}\n\\author{Hesen Chen}\n\\affiliation{%\n  \\institution{Alibaba Group}\n  \\city{Beijing}\n  \\country{China}}\n\\email{hesen.chs@alibaba-inc.com}\n\\begin{abstract}The rapid\n\\end{abstract}\n\\begin{CCSXML}\n\\ccsdesc[500]{Computing methodologies~Image representations}\n\\keywords{self-supervised,  ontrastive Learning, hierarchical projection, cross-level}\n\\begin{teaserfigure}\n\\end{teaserfigure}\n\\maketitle\n\\section{Introduction}\n\\begin{itemize}\n\\end{itemize}\n\\section{Related Work}\n\\label{gen_inst} Self-supervised\n\\section{Method}\n\\label{method}In this section,\n\\subsection{Framework} kkk\n\\subsection{Cross Contrastive Loss}\nSince $\\sZ^n$ are extracted\n\\subsection{Implementation details}\n\\textbf{Image augmentations} We use\n\\textbf{Architecture} We use\n\\textbf{Optimization} We adapt \n\\section{Experiments}\n\\label{experiments}In this section\n\\subsection{Linear and Semi-Supervised Evaluations on ImageNet}\n\\textbf{Linear evaluation on ImageNet} We firs\n\\textbf{Semi-supervised learning on ImageNet} We simply\n\\subsection{Transfer to other datasets and tasks}\n\\textbf{Image classification with fixed features} We follow\n\\section{Ablations} We present\n\\subsection{Influence of hierarchical projection head and cross contrastive loss} get out\n\\subsection{Levels and depth of projector network}\n\\end{center}\n\\caption{\\label{figure3} \\textbf{Different way of cross-correlation on 3 level hierarchical projection head.} '=' denotes stop gradient.}\n\\end{figure}\n\\subsection{Analyze of} In this\n\\textbf{Similarity between} Using SimSiam\n\\textbf{Feature similarity} We extracted\n\\section{Conclusion}\nWe propose HCCL\n\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{sample-base}\n\\end{document}\n\\endinput\n"
        },
        "params": [
            {
                "name": "inline",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "multiline",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "remove_header_mapper": {
        "name": "Remove Header",
        "description": "Mapper to remove headers at the beginning of documents in Latex\n    samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "%%\n%% This is file `sample-sigconf.tex',\n%% The first command in your LaTeX source must be the \\documentclass command.\n\\documentclass[sigconf,review,anonymous]{acmart}\n%% NOTE that a single column version is required for \n%% submission and peer review. This can be done by changing\n\\input{math_commands.tex}\n%% end of the preamble, start of the body of the document source.\n\\begin{document}\n%% The \"title\" command has an optional parameter,\n\\title{Hierarchical Cross Contrastive Learning of Visual Representations}\n%%\n%% The \"author\" command and its associated commands are used to define\n%% the authors and their affiliations.\n\\author{Hesen Chen}\n\\affiliation{%\n  \\institution{Alibaba Group}\n  \\city{Beijing}\n  \\country{China}}\n\\email{hesen.chs@alibaba-inc.com}\n%% By default, the full list of authors will be used in the page\n\\begin{abstract}The rapid\n\\end{abstract}\n\\begin{CCSXML}\n\\ccsdesc[500]{Computing methodologies~Image representations}\n%% Keywords. The author(s) should pick words that accurately describe\n\\keywords{self-supervised,  ontrastive Learning, hierarchical projection, cross-level}\n%% page.\n\\begin{teaserfigure}\n\\end{teaserfigure}\n%% This command processes the author and affiliation and title\n\\maketitle\n\\section{Introduction}\n\\begin{itemize}\n\\end{itemize}\n\\section{Related Work}\n\\label{gen_inst} Self-supervised\n\\section{Method}\n\\label{method}In this section,\n\\subsection{Framework} kkk\n\\subsection{Cross Contrastive Loss}\nSince $\\sZ^n$ are extracted\n\\subsection{Implementation details}\n\\textbf{Image augmentations} We use\n\\textbf{Architecture} We use\n\\textbf{Optimization} We adapt \n\\section{Experiments}\n\\label{experiments}In this section\n\\subsection{Linear and Semi-Supervised Evaluations on ImageNet}\n\\textbf{Linear evaluation on ImageNet} We firs\n\\textbf{Semi-supervised learning on ImageNet} We simply\n\\subsection{Transfer to other datasets and tasks}\n\\textbf{Image classification with fixed features} We follow\n\\section{Ablations} We present\n\\subsection{Influence of hierarchical projection head and cross contrastive loss} get out\n\\subsection{Levels and depth of projector network}\n\\end{center}\n\\caption{\\label{figure3} \\textbf{Different way of cross-correlation on 3 level hierarchical projection head.} '=' denotes stop gradient.}\n\\end{figure}\n\\subsection{Analyze of} In this\n\\textbf{Similarity between} Using SimSiam\n\\textbf{Feature similarity} We extracted\n\\section{Conclusion}\nWe propose HCCL\n\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{sample-base}\n\\end{document}\n\\endinput\n%%\n%% End of file `sample-sigconf.tex'.\n",
            "after": "\\section{Introduction}\n\\begin{itemize}\n\\end{itemize}\n\\section{Related Work}\n\\label{gen_inst} Self-supervised\n\\section{Method}\n\\label{method}In this section,\n\\subsection{Framework} kkk\n\\subsection{Cross Contrastive Loss}\nSince $\\sZ^n$ are extracted\n\\subsection{Implementation details}\n\\textbf{Image augmentations} We use\n\\textbf{Architecture} We use\n\\textbf{Optimization} We adapt \n\\section{Experiments}\n\\label{experiments}In this section\n\\subsection{Linear and Semi-Supervised Evaluations on ImageNet}\n\\textbf{Linear evaluation on ImageNet} We firs\n\\textbf{Semi-supervised learning on ImageNet} We simply\n\\subsection{Transfer to other datasets and tasks}\n\\textbf{Image classification with fixed features} We follow\n\\section{Ablations} We present\n\\subsection{Influence of hierarchical projection head and cross contrastive loss} get out\n\\subsection{Levels and depth of projector network}\n\\end{center}\n\\caption{\\label{figure3} \\textbf{Different way of cross-correlation on 3 level hierarchical projection head.} '=' denotes stop gradient.}\n\\end{figure}\n\\subsection{Analyze of} In this\n\\textbf{Similarity between} Using SimSiam\n\\textbf{Feature similarity} We extracted\n\\section{Conclusion}\nWe propose HCCL\n\\clearpage\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{sample-base}\n\\end{document}\n\\endinput\n%%\n%% End of file `sample-sigconf.tex'.\n"
        },
        "params": [
            {
                "name": "drop_no_head",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "remove_long_words_mapper": {
        "name": "Long Words Cleaner",
        "description": "Mapper to remove long words within a specific range.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "This paper a novel eqeqweqwewqeqwe121e1 method on LLM pretrain.",
            "after": "This paper novel method LLM pretrain."
        },
        "params": [
            {
                "name": "min_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 1
            },
            {
                "name": "max_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 9999999
            }
        ]
    },
    "remove_non_chinese_character_mapper": {
        "name": "Non Chinese Cleaner",
        "description": "Mapper to remove non chinese Character in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "ğŸ‘Š    æ‰€æœ‰çš„éæ±‰å­—a44shéƒ½12@46hä¼šè¢«*&â€¦â€¦*qb^4525å»æ‰",
            "after": "æ‰€æœ‰çš„éæ±‰å­—éƒ½ä¼šè¢«å»æ‰"
        },
        "params": [
            {
                "name": "keep_alphabet",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "keep_number",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "keep_punc",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "remove_repeat_sentences_mapper": {
        "name": "Sentence De-duplication",
        "description": "Mapper to remove repeat sentences in text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚å°æ˜è¯´ï¼šâ€œä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œæˆ‘ä»¬å»æµ·è¾¹å§ã€‚â€ å°çº¢å›ç­”è¯´ï¼šâ€œå¥½ä¸»æ„ï¼â€ ä½†æ˜¯ï¼Œå°æè§‰å¾—ï¼šâ€œä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œæˆ‘ä»¬å»çˆ¬å±±å§ã€‚â€ ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚æ˜¨å¤©ä¸‹äº†ä¸€æ•´å¤©çš„é›¨ï¼Œä»Šå¤©ç»ˆäºæ”¾æ™´äº†ã€‚æ˜¨å¤©ä¸‹äº†ä¸€æ•´å¤©çš„é›¨ï¼Œä»Šå¤©ç»ˆäºæ”¾æ™´äº†ã€‚",
            "after": "ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚å°æ˜è¯´ï¼šâ€œä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œæˆ‘ä»¬å»æµ·è¾¹å§ã€‚â€ å°çº¢å›ç­”è¯´ï¼šâ€œå¥½ä¸»æ„ï¼â€ ä½†æ˜¯ï¼Œå°æè§‰å¾—ï¼šâ€œä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œæˆ‘ä»¬å»çˆ¬å±±å§ã€‚â€æ˜¨å¤©ä¸‹äº†ä¸€æ•´å¤©çš„é›¨ï¼Œä»Šå¤©ç»ˆäºæ”¾æ™´äº†ã€‚"
        },
        "params": [
            {
                "name": "lowercase",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "ignore_special_character",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "min_repeat_sentence_length",
                "type": "INTEGER",
                "option_values": null,
                "value": 2
            }
        ]
    },
    "remove_specific_chars_mapper": {
        "name": "Specific Chars Cleaner",
        "description": "Mapper to clean specific chars in text samples. now support: â—†â—â– â–ºâ–¼â–²â–´âˆ†â–»â–·â–â™¡â–¡",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "å¤šä¸ªâ—â– â–ºâ–¼è¿™æ ·çš„ç‰¹æ®Šå­—ç¬¦å¯ä»¥â–ºâ–¼â–²â–´âˆ†å—ï¼Ÿ",
            "after": "å¤šä¸ªè¿™æ ·çš„ç‰¹æ®Šå­—ç¬¦å¯ä»¥å—ï¼Ÿ"
        },
        "params": [
            {
                "name": "chars_to_remove",
                "type": "LIST",
                "option_values": null,
                "value": [
                    "â—†â—â– â–ºâ–¼â–²â–´âˆ†â–»â–·â–â™¡â–¡"
                ]
            }
        ]
    },
    "remove_table_text_mapper": {
        "name": "Table Texts Cleaner",
        "description": "\n    Mapper to remove table texts from text samples.\n\n    Regular expression is used to remove tables in the range of column\n    number of tables.\n    ",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "This is a table:\nç¼–å· åˆ†è¡Œ è¥è¿èµ„é‡‘1 è¥è¿èµ„é‡‘2 è¥è¿èµ„é‡‘3 è¥è¿èµ„é‡‘4 è¥è¿èµ„é‡‘5\nâ‘  åŒ—äº¬åˆ†è¡Œ 495,000,000.00 200,000,000.00 295,000,000.00 - 495,000,000.00\nâ‘¡ å¤§è¿åˆ†è¡Œ 440,000,000.00 100,000,000.00 340,000,000.00 - 440,000,000.00\nâ‘¢ é‡åº†åˆ†è¡Œ 500,000,000.00 100,000,000.00 400,000,000.00 - 500,000,000.00\nâ‘£ å—äº¬åˆ†è¡Œ 430,000,000.00 100,000,000.00 330,000,000.00 - 430,000,000.00\nâ‘¤ é’å²›åˆ†è¡Œ 500,000,000.00 - 100,159,277.60 399,840,722.40 500,000,000.00\nThe end of the table.",
            "after": "This is a table:\nThe end of the table."
        },
        "params": [
            {
                "name": "min_col",
                "type": "from_2_to_20",
                "option_values": null,
                "value": 2
            },
            {
                "name": "max_col",
                "type": "from_2_to_20",
                "option_values": null,
                "value": 20
            }
        ]
    },
    "remove_words_with_incorrect_substrings_mapper": {
        "name": "Incorrect Substring Cleaner",
        "description": "Mapper to remove words with incorrect substrings.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "è¯·ç”¨ç™¾åº¦www.baidu.comè¿›è¡Œæœç´¢",
            "after": "è¯·ç”¨ç™¾åº¦www.baiduè¿›è¡Œæœç´¢"
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "en",
                        "label": "en"
                    },
                    {
                        "key": "zh",
                        "label": "zh"
                    }
                ],
                "value": "en"
            },
            {
                "name": "tokenization",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "substrings",
                "type": "LIST",
                "option_values": null,
                "value": [
                    "http",
                    "www",
                    ".com",
                    "href",
                    "//"
                ]
            }
        ]
    },
    "replace_content_mapper": {
        "name": "Content Replacement",
        "description": "Mapper to replace all content in the text that matches\n    a specific regular expression pattern with a designated\n    replacement string.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "å¤šä¸ªâ—â– â–ºâ–¼è¿™æ ·çš„ç‰¹æ®Šå­—ç¬¦å¯ä»¥â–ºâ–¼â–²â–´âˆ†å—ï¼Ÿ",
            "after": "å¤šä¸ª<SPEC>â–ºâ–¼è¿™æ ·çš„ç‰¹æ®Šå­—ç¬¦å¯ä»¥â–ºâ–¼â–²â–´âˆ†å—ï¼Ÿ"
        },
        "params": [
            {
                "name": "pattern",
                "type": "LIST",
                "option_values": null,
                "value": []
            },
            {
                "name": "repl",
                "type": "LIST",
                "option_values": null,
                "value": []
            }
        ]
    },
    "sentence_split_mapper": {
        "name": "Sentence Spliter",
        "description": "Mapper to split text samples to sentences.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "Smithfield employs 3,700 people at its plant in Sioux Falls, South Dakota. The plant slaughters 19,500 pigs a day â€” 5 percent of U.S. pork.",
            "after": "Smithfield employs 3,700 people at its plant in Sioux Falls, South Dakota.\nThe plant slaughters 19,500 pigs a day â€” 5 percent of U.S. pork."
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "en",
                        "label": "en"
                    },
                    {
                        "key": "zh",
                        "label": "zh"
                    }
                ],
                "value": "en"
            }
        ]
    },
    "whitespace_normalization_mapper": {
        "name": "Whitespace Normalizor",
        "description": "\n    Mapper to normalize different kinds of whitespaces to whitespace ' ' (0x20)\n    in text samples.\n\n    Different kinds of whitespaces can be found here:\n    https://en.wikipedia.org/wiki/Whitespace_character\n    ",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "hello world",
            "after": "world hello"
        },
        "params": []
    },
    "alphanumeric_filter": {
        "name": "Alphabet/Numeric Ratio Filter",
        "description": "Filter to keep samples with alphabet/numeric ratio within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "emojiè¡¨æƒ…æµ‹è¯•ä¸‹ğŸ˜Šï¼ŒğŸ˜¸31231\n",
            "after": ""
        },
        "params": [
            {
                "name": "tokenization",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "min_ratio",
                "type": "FLOAT",
                "option_values": null,
                "value": 0.1
            },
            {
                "name": "max_ratio",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 999999
            }
        ]
    },
    "average_line_length_filter": {
        "name": "Average Line Length Filter",
        "description": "Filter to keep samples with average line length within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "short",
            "after": ""
        },
        "params": [
            {
                "name": "min_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "max_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 1200
            }
        ]
    },
    "character_repetition_filter": {
        "name": "Char-Level Repetition Ratio Filter",
        "description": "Filter to keep samples with char-level n-gram repetition ratio within a\n    specific range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Today is Sund Sund Sund Sund Sund Sunda and it's a happy day!",
            "after": ""
        },
        "params": [
            {
                "name": "rep_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "min_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0
            },
            {
                "name": "max_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.6
            }
        ]
    },
    "flagged_words_filter": {
        "name": "Flagged-Word Ratio Filter",
        "description": "Filter to keep samples with flagged-word ratio less than a specific max\n    value.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "åŸºäºå‰ä¸€æ­¥ç»“æœï¼Œé™¤æ‰éª‚äººã€è„å­—ç­‰æ±¡ç§½æ•°æ®å’Œæ•æ„Ÿè¯",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "en",
                        "label": "en"
                    },
                    {
                        "key": "zh",
                        "label": "zh"
                    }
                ],
                "value": "zh"
            },
            {
                "name": "tokenization",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "max_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.001
            },
            {
                "name": "use_words_aug",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "language_id_score_filter": {
        "name": "Specific Language Filter",
        "description": "\n    Filter to keep samples in a specific language with confidence score\n    larger than a specific min value.\n    ",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Today is Sund Sund Sund Sunda and it's a happy day!\nYou know",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "zh",
                        "label": "zh"
                    },
                    {
                        "key": "en",
                        "label": "en"
                    },
                    {
                        "key": "fr",
                        "label": "fr"
                    },
                    {
                        "key": "de",
                        "label": "de"
                    }
                ],
                "value": "zh"
            },
            {
                "name": "min_score",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.8
            }
        ]
    },
    "maximum_line_length_filter": {
        "name": "Maximum Line Length Filter",
        "description": "Filter to keep samples with maximum line length within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Today is Sund Sund Sund Sunda and it's a happy day!\nYou know",
            "after": ""
        },
        "params": [
            {
                "name": "min_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "max_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 7328
            }
        ]
    },
    "perplexity_filter": {
        "name": "Perplexity Score Filter",
        "description": "Filter to keep samples with perplexity score less than a specific max\n    value.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Today is Sund Sund Sund Sunda and it's a happy day!\nYou know",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "en",
                        "label": "en"
                    },
                    {
                        "key": "zh",
                        "label": "zh"
                    }
                ],
                "value": "en"
            },
            {
                "name": "max_ppl",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 8000
            }
        ]
    },
    "special_characters_filter": {
        "name": "Special-Char Ratio Filter",
        "description": "Filter to keep samples with special-char ratio within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "emojiè¡¨æƒ…æµ‹è¯•ä¸‹ğŸ˜Šï¼ŒğŸ˜¸31231",
            "after": ""
        },
        "params": [
            {
                "name": "min_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0
            },
            {
                "name": "max_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.842
            }
        ]
    },
    "specified_field_filter": {
        "name": "Specified Field Information Filter",
        "description": "\n    Filter based on specified field information.\n\n    If the specified field information in the sample is not within the\n    specified target value, the sample will be filtered.\n    ",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "{'text': 'ä¸­æ–‡ä¹Ÿæ˜¯ä¸€ä¸ªå­—ç®—ä¸€ä¸ªé•¿åº¦','meta': {    'suffix': '.txt',    'star': 100}}",
            "after": ""
        },
        "params": [
            {
                "name": "field_key",
                "type": "STRING",
                "option_values": null,
                "value": ""
            },
            {
                "name": "target_value",
                "type": "LIST",
                "option_values": null,
                "value": []
            }
        ]
    },
    "specified_numeric_field_filter": {
        "name": "Specified Numeric Field Filter",
        "description": "\n    Filter based on specified numeric field information.\n\n    If the specified numeric information in the sample is not within the\n    specified range, the sample will be filtered.\n    ",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "{'text': 'ä¸­æ–‡ä¹Ÿæ˜¯ä¸€ä¸ªå­—ç®—ä¸€ä¸ªé•¿åº¦','meta': {    'suffix': '.txt',    'star': 100}}",
            "after": ""
        },
        "params": [
            {
                "name": "field_key",
                "type": "STRING",
                "option_values": null,
                "value": ""
            },
            {
                "name": "min_value",
                "type": "FLOAT",
                "option_values": null,
                "value": -999999
            },
            {
                "name": "max_value",
                "type": "FLOAT",
                "option_values": null,
                "value": 999999
            }
        ]
    },
    "stopwords_filter": {
        "name": "Stopword Ratio Filter",
        "description": "Filter to keep samples with stopword ratio larger than a specific min\n    value.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "?",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "en",
                        "label": "en"
                    },
                    {
                        "key": "zh",
                        "label": "zh"
                    }
                ],
                "value": "zh"
            },
            {
                "name": "tokenization",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            },
            {
                "name": "min_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.3
            },
            {
                "name": "use_words_aug",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            }
        ]
    },
    "suffix_filter": {
        "name": "Specified Suffix Filter",
        "description": "Filter to keep samples with specified suffix.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "{'text': 'ä¸­æ–‡ä¹Ÿæ˜¯ä¸€ä¸ªå­—ç®—ä¸€ä¸ªé•¿åº¦',Fields.suffix: '.txt'}",
            "after": ""
        },
        "params": [
            {
                "name": "suffixes",
                "type": "LIST",
                "option_values": null,
                "value": []
            }
        ]
    },
    "text_action_filter": {
        "name": "Texts Contain Actions Filter",
        "description": "Filter to keep texts those contain actions in the text..",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "æˆ‘æœ‰ä¸€åªçŒ«ï¼Œå®ƒæ˜¯ä¸€åªçŒ«",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "zh",
                        "label": "zh"
                    },
                    {
                        "key": "en",
                        "label": "en"
                    }
                ],
                "value": "zh"
            },
            {
                "name": "min_action_num",
                "type": "INTEGER",
                "option_values": null,
                "value": 1
            }
        ]
    },
    "text_entity_dependency_filter": {
        "name": "Texts Containing Entities Filter",
        "description": "\n    Identify the entities in the text which are independent with other token,\n    and filter them. The text containing no entities will be omitted.\n    ",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "ä¸Šä¸Šä¸‹ä¸‹å·¦å·¦å³å³",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "zh",
                        "label": "zh"
                    },
                    {
                        "key": "en",
                        "label": "en"
                    }
                ],
                "value": "zh"
            },
            {
                "name": "min_dependency_num",
                "type": "INTEGER",
                "option_values": null,
                "value": 1
            },
            {
                "name": "any_or_all",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "all",
                        "label": "all"
                    },
                    {
                        "key": "any",
                        "label": "any"
                    }
                ],
                "value": "all"
            }
        ]
    },
    "text_length_filter": {
        "name": "Total Text Length Filter",
        "description": "Filter to keep samples with total text length within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Today is Sund Sund Sund Sund Sund Sunda and it's a happy day!",
            "after": ""
        },
        "params": [
            {
                "name": "min_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "max_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 136028
            }
        ]
    },
    "token_num_filter": {
        "name": "Total Token Number Filter",
        "description": "Filter to keep samples with total token number within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Today is Sund Sund Sund Sund Sund Sunda and it's a happy day!",
            "after": ""
        },
        "params": [
            {
                "name": "hf_tokenizer",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "EleutherAI/pythia-6.9b-deduped",
                        "label": "EleutherAI/pythia-6.9b-deduped"
                    }
                ],
                "value": "EleutherAI/pythia-6.9b-deduped"
            },
            {
                "name": "min_num",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "max_num",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 999999
            }
        ]
    },
    "word_repetition_filter": {
        "name": "Word-Level Repetition Ratio Filter",
        "description": "Filter to keep samples with word-level n-gram repetition ratio within a\n    specific range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "æ ¹æ®ç®—å­ä½¿ç”¨ä½¿ç”¨ä½¿ç”¨ä½¿ç”¨å®‰è£…æ–¹æ¡ˆç¡®å®š",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "zh",
                        "label": "zh"
                    },
                    {
                        "key": "en",
                        "label": "en"
                    }
                ],
                "value": "en"
            },
            {
                "name": "tokenization",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "rep_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "min_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0
            },
            {
                "name": "max_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.5981
            }
        ]
    },
    "words_num_filter": {
        "name": "Total Words Number Filter",
        "description": "Filter to keep samples with total words number within a specific\n    range.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "æ ¹æ®ç®—å­ä½¿ç”¨ä½¿ç”¨ä½¿ç”¨ä½¿ç”¨å®‰è£…æ–¹æ¡ˆç¡®å®š",
            "after": ""
        },
        "params": [
            {
                "name": "lang",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "zh",
                        "label": "zh"
                    },
                    {
                        "key": "en",
                        "label": "en"
                    }
                ],
                "value": "en"
            },
            {
                "name": "tokenization",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "min_num",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 20
            },
            {
                "name": "max_num",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 23305
            }
        ]
    },
    "document_deduplicator": {
        "name": "Document Deduplicator(MD5 Hash)",
        "description": "\n    Deduplicator to deduplicate samples at document-level using exact matching.\n\n    Using md5 hash to deduplicate samples.\n    ",
        "type": "Deduplicator",
        "group": "",
        "samples": {
            "before": "{    'text':    'This paper proposed a novel method on LLM pretraining.'},{    'text':    'This paper proposed a novel method on LLM pretraining.'}",
            "after": "{    'text':    'This paper proposed a novel method on LLM pretraining.'},"
        },
        "params": [
            {
                "name": "lowercase",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "ignore_non_character",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "document_minhash_deduplicator": {
        "name": "Document Deduplicator(MinHashLSH)",
        "description": "\n    Deduplicator to deduplicate samples at document-level using MinHashLSH.\n\n    Different from simhash, minhash is stored as bytes, so they won't be\n    kept in the final dataset.\n    ",
        "type": "Deduplicator",
        "group": "",
        "samples": {
            "before": "",
            "after": ""
        },
        "params": [
            {
                "name": "tokenization",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "space",
                        "label": "space"
                    },
                    {
                        "key": "punctuation",
                        "label": "punctuation"
                    },
                    {
                        "key": "character",
                        "label": "character"
                    },
                    {
                        "key": "sentencepiece",
                        "label": "sentencepiece"
                    }
                ],
                "value": "character"
            },
            {
                "name": "window_size",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 5
            },
            {
                "name": "lowercase",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "ignore_pattern",
                "type": "STRING",
                "option_values": null,
                "value": null
            },
            {
                "name": "num_permutations",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 256
            },
            {
                "name": "jaccard_threshold",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": 0.7
            },
            {
                "name": "num_bands",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            },
            {
                "name": "num_rows_per_band",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            },
            {
                "name": "tokenizer_model",
                "type": "STRING",
                "option_values": null,
                "value": null
            }
        ]
    },
    "document_simhash_deduplicator": {
        "name": "Document Deduplicator(SimHash)",
        "description": "Deduplicator to deduplicate samples at document-level using SimHash.",
        "type": "Deduplicator",
        "group": "",
        "samples": {
            "before": "",
            "after": ""
        },
        "params": [
            {
                "name": "tokenization",
                "type": "STRING",
                "option_values": [
                    {
                        "key": "space",
                        "label": "space"
                    },
                    {
                        "key": "punctuation",
                        "label": "punctuation"
                    },
                    {
                        "key": "character",
                        "label": "character"
                    }
                ],
                "value": "character"
            },
            {
                "name": "window_size",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 4
            },
            {
                "name": "lowercase",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            },
            {
                "name": "ignore_pattern",
                "type": "STRING",
                "option_values": null,
                "value": "\\p{P}"
            },
            {
                "name": "num_blocks",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 10
            },
            {
                "name": "hamming_distance",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 8
            }
        ]
    },
    "frequency_specified_field_selector": {
        "name": "Sorted Frequency Selector",
        "description": "Selector to select samples based on the sorted frequency of specified\n    field.",
        "type": "Selector",
        "group": "",
        "samples": {
            "before": "{'text': 'ï¼Œã€‚ã€â€â€â€œÂ«Â»ï¼‘ã€ã€Œã€Šã€‹Â´âˆ¶ï¼šï¼Ÿï¼','count': None,'meta': {    'suffix': '.html',    'key1': {        'key2': {            'count': 18        },        'count': 48    }}}",
            "after": ""
        },
        "params": [
            {
                "name": "field_key",
                "type": "STRING",
                "option_values": null,
                "value": ""
            },
            {
                "name": "top_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": null
            },
            {
                "name": "topk",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            },
            {
                "name": "reverse",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "random_selector": {
        "name": "Random Selector",
        "description": "Selector to random select samples. ",
        "type": "Selector",
        "group": "",
        "samples": {
            "before": "{'text': 'ï¼Œã€‚ã€â€â€â€œÂ«Â»ï¼‘ã€ã€Œã€Šã€‹Â´âˆ¶ï¼šï¼Ÿï¼','count': None,'meta': {    'suffix': '.html',    'key1': {        'key2': {            'count': 18        },        'count': 48    }}}",
            "after": ""
        },
        "params": [
            {
                "name": "select_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": null
            },
            {
                "name": "select_num",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            }
        ]
    },
    "range_specified_field_selector": {
        "name": "Sorted Range Selector",
        "description": "Selector to select a range of samples based on the sorted\n    specified field value from smallest to largest. ",
        "type": "Selector",
        "group": "",
        "samples": {
            "before": "{'text': 'ï¼Œã€‚ã€â€â€â€œÂ«Â»ï¼‘ã€ã€Œã€Šã€‹Â´âˆ¶ï¼šï¼Ÿï¼','count': None,'meta': {    'suffix': '.html',    'key1': {        'key2': {            'count': 18        },        'count': 48    }}}",
            "after": ""
        },
        "params": [
            {
                "name": "field_key",
                "type": "STRING",
                "option_values": null,
                "value": ""
            },
            {
                "name": "lower_percentile",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": null
            },
            {
                "name": "upper_percentile",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": null
            },
            {
                "name": "lower_rank",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            },
            {
                "name": "upper_rank",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            }
        ]
    },
    "topk_specified_field_selector": {
        "name": "Top Samples Selector",
        "description": "Selector to select top samples based on the sorted specified field\n    value.",
        "type": "Selector",
        "group": "",
        "samples": {
            "before": "{'text': 'ï¼Œã€‚ã€â€â€â€œÂ«Â»ï¼‘ã€ã€Œã€Šã€‹Â´âˆ¶ï¼šï¼Ÿï¼','count': None,'meta': {    'suffix': '.html',    'key1': {        'key2': {            'count': 18        },        'count': 48    }}}",
            "after": ""
        },
        "params": [
            {
                "name": "field_key",
                "type": "STRING",
                "option_values": null,
                "value": ""
            },
            {
                "name": "top_ratio",
                "type": "ClosedUnitInterval",
                "option_values": null,
                "value": null
            },
            {
                "name": "topk",
                "type": "PositiveFloat",
                "option_values": null,
                "value": null
            },
            {
                "name": "reverse",
                "type": "BOOLEAN",
                "option_values": null,
                "value": true
            }
        ]
    },
    "text_high_score_filter": {
        "name": "Score data filtering",
        "description": "Filter text samples based on score value range in specified field.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "",
            "after": ""
        },
        "params": [
            {
                "name": "score_field",
                "type": "LIST",
                "option_values": null,
                "value": "score"
            },
            {
                "name": "min_score",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 0.6
            },
            {
                "name": "max_score",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 2
            }
        ]
    },
    "text_bloom_filter": {
        "name": "Data Bloom filtering to remove duplicates",
        "description": "Filter to deduplicate samples using Bloom Filter.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "A data set containing duplicate text, such as the same sentence that occurs multiple times",
            "after": "A deduplicated data set that keeps only one instance of each unique text"
        },
        "params": [
            {
                "name": "hash_func",
                "type": "LIST",
                "option_values": null,
                "value": "md5"
            },
            {
                "name": "initial_capacity",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 100
            }
        ]
    },
    "make_cosmopedia_mapper": {
        "name": "Style data synthesis",
        "description": "Mapper to generate synthetic tutorial data from seed text samples.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "How to Train Your Dog to Sit",
            "after": "Training your dog to sit is one of the most fundamental commands..."
        },
        "params": [
            {
                "name": "web_text_max_len",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 800
            }
        ]
    },
    "gather_generated_data": {
        "name": "Data aggregation generation",
        "description": "Filter for collecting and processing generated data.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Based on the results of the previous step, remove the | | and < | im_end | > characters and filter out data with empty content",
            "after": ""
        },
        "params": [
            {
                "name": "is_drop",
                "type": "BOOLEAN",
                "option_values": null,
                "value": false
            }
        ]
    },
    "encode_and_get_nearest_mapper": {
        "name": "Data sample vector encoding search",
        "description": "Encode texts and find nearest neighbours using Faiss.",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "The dataset contains text data first_prompt fields, such as ['What is artificial intelligence?', 'How does machine learning work?']",
            "after": "The dataset adds embedding, nn_indices, and nn_scores fields containing vector representations of text and nearest neighbor information"
        },
        "params": []
    },
    "gather_generated_data_filter": {
        "name": "gather_generated_data_filter",
        "description": "Filter for collecting and processing generated data.",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Based on the results of the previous step, remove the | | and < | im_end | > characters and filter to get the empty content data.",
            "after": ""
        },
        "params": []
    },
    "annotate_edu_train_bert_scorer_mapper": {
        "name": "annotate_edu_train_bert_scorer_mapper",
        "description": "Annotate Edu Train BERT Scorer",
        "type": "Filter",
        "group": "",
        "samples": {
            "before": "Here is a more concise translation of the provided sentence:'Score a field and add a _score field for the result.'",
            "after": ""
        },
        "params": [
            {
                "name": "auth_token",
                "type": "LIST",
                "option_values": null,
                "value": ""
            },
            {
                "name": "model_name",
                "type": "LIST",
                "option_values": null,
                "value": "text-embedding-v4"
            },
            {
                "name": "dimensions",
                "type": "PositiveFloat",
                "option_values": null,
                "value": "1024"
            },
            {
                "name": "model_url",
                "type": "LIST",
                "option_values": null,
                "value": "https://dashscope.aliyuncs.com/compatible-mode/v1"
            },
            {
                "name": "query_text",
                "type": "LIST",
                "option_values": null,
                "value": "What is Deep Learning?"
            }
        ]
    },
    "dedup_and_save_deduplicator": {
        "name": "dedup_and_save_deduplicator",
        "description": "A deduplicator based on graph connectivity. It constructs a similarity graph by connecting samples with similarity scores above the threshold, then keeps only one sample (with minimum index) from each connected component. Suitable for datasets with pre-computed nearest neighbor similarity information.",
        "type": "Deduplicator",
        "group": "",
        "samples": {
            "before": "",
            "after": ""
        },
        "params": [
            {
                "name": "similarity_threshold",
                "type": "PositiveFloat",
                "option_values": null,
                "value": 0.5
            }
        ]
    },
    "pipeline_magpie_zh_mapper": {
        "name": "pipeline_magpie_zh_mapper",
        "description": "Using the deepseek-v2.5 or qwen2.5 model, generate multi-round dialogue data based on the manually designed system_prompt corresponding to multiple tasks",
        "type": "Mapper",
        "group": "",
        "samples": {
            "before": "",
            "after": ""
        },
        "params": [
            {
                "name": "model_name",
                "type": "LIST",
                "option_values": null,
                "value": "qwen-plus"
            },
            {
                "name": "auth_token",
                "type": "LIST",
                "option_values": null,
                "value": ""
            },
            {
                "name": "model_url",
                "type": "LIST",
                "option_values": null,
                "value": "https://dashscope.aliyuncs.com/compatible-mode/v1"
            }
        ]
    }
}